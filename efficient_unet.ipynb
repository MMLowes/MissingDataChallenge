{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lowes\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from types import SimpleNamespace\n",
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models.efficient_unet import AbstractUNet\n",
    "from dataset import CatDataset\n",
    "from inpaint_tools import read_file_list\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"unet\": {\"block\": \"ffmmm\", #m=MBConv,f=FusedMBConv,u=Unet \n",
    "                    \"act\": \"silu\",\n",
    "                    \"res_mode\": \"cat\", #cat, add\n",
    "                    \"init_mode\": \"effecientnetv2\",\n",
    "                    \"downscale_mode\": \"avgpool\",\n",
    "                    \"upscale_mode\": \"bilinear\",\n",
    "                    \"input_channels\": 4,\n",
    "                    \"output_channels\": 3,\n",
    "                    \"num_blocks\": 5,\n",
    "                    \"num_c\": [8,16,32,48,64],\n",
    "                    \"num_repeat\": [1,2,2,4,4],\n",
    "                    \"expand_ratio\": [1,4,4,6,6],\n",
    "                    \"SE\": [0,0,1,1,1]\n",
    "                }}\n",
    "\n",
    "args = {\"unet\": {\"block\": \"ffmmm\", #m=MBConv,f=FusedMBConv,u=Unet \n",
    "                    \"act\": \"silu\",\n",
    "                    \"res_mode\": \"cat\", #cat, add\n",
    "                    \"init_mode\": \"effecientnetv2\",\n",
    "                    \"downscale_mode\": \"avgpool\",\n",
    "                    \"upscale_mode\": \"bilinear\",\n",
    "                    \"input_channels\": 4,\n",
    "                    \"output_channels\": 3,\n",
    "                    \"num_blocks\": 4,\n",
    "                    \"num_c\": [16,32,64,96],\n",
    "                    \"num_repeat\": [1,2,2,4],\n",
    "                    \"expand_ratio\": [1,4,4,6],\n",
    "                    \"SE\": [0,1,1,1]\n",
    "                }}\n",
    "args_n = json.loads(json.dumps(args), object_hook=lambda item: SimpleNamespace(**item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "net = AbstractUNet(args_n).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 360, 360])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.zeros((1,4,360,360)).to(device)\n",
    "output = net(test)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([4, 360, 360]), torch.Size([1, 360, 360]), torch.Size([3, 360, 360])]\n"
     ]
    }
   ],
   "source": [
    "settings = {\n",
    "\t\"team_data\":\n",
    "\t{\n",
    "\t\t\"name\": \"YourTeamNameHere\"\n",
    "\t},\n",
    "    \"training_parms\": {\n",
    "\t\t\"method\": \"YourMethodHere\",\n",
    "\t\t\"dummy_value\": 1000\n",
    "    },\n",
    "    \"dirs\": {\n",
    "            \"input_data_dir\": \"C:/Users/lowes/OneDrive/Skrivebord/DTU/summer_school_23/MissingDataChallenge/data/\",\n",
    "\t\t\t\"output_data_dir\": \"missing_data_output/\"\n",
    "\t},\n",
    "\t\"challenge_server\": {\n",
    "\t\t\"address\": \"http://fungi.compute.dtu.dk:8080\"\n",
    "\t},\n",
    "\t\"data_set\": \"training\",\n",
    "\t\"batch_size\": 4,\n",
    "\t\"num_workers\": 0,\n",
    "}\n",
    "\n",
    "\n",
    "dataset_train = CatDataset(settings)\n",
    "print([d.shape for d in dataset_train[0]])\n",
    "\n",
    "dl = DataLoader(dataset_train, \n",
    "\t\t\t\tbatch_size=settings[\"batch_size\"],\n",
    "                shuffle=True,\n",
    "                num_workers=settings[\"num_workers\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  20%|█▉        | 248/1242 [01:12<04:51,  3.41batch/s, loss=0.0381]"
     ]
    }
   ],
   "source": [
    "from inpaint_tools import save_inp_out, save_image\n",
    "settings[\"data_set\"] = \"training\"\n",
    "dataset_train = CatDataset(settings)\n",
    "dl_train = DataLoader(dataset_train, \n",
    "\t\t\t\tbatch_size=settings[\"batch_size\"],\n",
    "                shuffle=True,\n",
    "                num_workers=settings[\"num_workers\"])\n",
    "\n",
    "settings[\"data_set\"] = \"validation_200\"\n",
    "dataset_val = CatDataset(settings)\n",
    "dl_val = DataLoader(dataset_val, \n",
    "\t\t\t\tbatch_size=settings[\"batch_size\"],\n",
    "                shuffle=True,\n",
    "                num_workers=settings[\"num_workers\"])\n",
    "\n",
    "# Create the model, loss function, and optimizer\n",
    "save_every = 4\n",
    "NUM_EPOCHS = 12\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AbstractUNet(args_n).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "val_loss = \"NA\"\n",
    "save_dir = os.path.join(settings[\"dirs\"][\"output_data_dir\"], \"efficient_unet\")\n",
    "save_image_dir = os.path.join(save_dir,\"train_images\")\n",
    "pathlib.Path(save_image_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Create a progress bar using tqdm\n",
    "    with tqdm.tqdm(dl_train, unit=\"batch\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "            model_input, mask, image = batch\n",
    "            model_input, mask, image = model_input.to(device), mask.to(device), image.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(model_input)\n",
    "\n",
    "            loss = criterion(outputs*mask, image*mask)\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update progress bar description with loss\n",
    "            tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "            # Accumulate loss for this epoch\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    # Calculate and print average loss for the epoch\n",
    "    average_loss = running_loss / len(dl_train)\n",
    "\n",
    "    model.eval()\n",
    "    running_val = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in dl_val:\n",
    "            model_input, mask, image = batch\n",
    "            model_input, mask, image = model_input.to(device), mask.to(device), image.to(device)\n",
    "\n",
    "            outputs = model(model_input)\n",
    "\n",
    "            loss = criterion(outputs*mask, image*mask)\n",
    "            running_val += loss.item()\n",
    "\n",
    "    avg_val = running_val / len(dl_val)\n",
    "    print(\"validation loss: \", avg_val)\n",
    "    \n",
    "    save_image_name = os.path.join(save_image_dir,f\"val_epoch_{epoch+1}.png\")\n",
    "    save_image(save_image_name,outputs[0],mask[0],image[0])\n",
    "    save_inp_out(save_image_name, outputs[0],mask[0],model_input[0])\n",
    "\n",
    "    if (epoch+1)%save_every:\n",
    "        save_net = os.path.join(save_dir,\"models\",f\"epoch_{epoch+1}.pt\")\n",
    "        torch.save(model.state_dict(), save_net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_net = os.path.join(save_dir,\"models\",f\"epoch_{epoch+1}.pt\")\n",
    "# pathlib.Path(os.path.join(save_dir,\"models\")).mkdir(parents=True, exist_ok=True)\n",
    "# torch.save(model.state_dict(), save_net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AbstractUNet(\n",
       "  (first_conv): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (last_conv): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (DownBlocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): FusedMBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): FusedMBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): FusedMBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): SiLU()\n",
       "          (6): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (7): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): SiLU()\n",
       "          (6): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (7): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): SiLU()\n",
       "          (6): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=384, out_features=16, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=16, out_features=384, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (7): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): SiLU()\n",
       "          (6): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=384, out_features=16, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=16, out_features=384, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (7): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): SiLU()\n",
       "          (6): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=384, out_features=16, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=16, out_features=384, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (7): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): SiLU()\n",
       "          (6): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=384, out_features=16, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=16, out_features=384, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (7): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (UpBlocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): FusedMBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): FusedMBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): FusedMBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): SiLU()\n",
       "          (6): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=16, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=16, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (7): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): SiLU()\n",
       "          (6): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (7): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): SiLU()\n",
       "          (6): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=384, out_features=16, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=16, out_features=384, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (7): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): SiLU()\n",
       "          (6): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=384, out_features=16, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=16, out_features=384, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (7): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): SiLU()\n",
       "          (6): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=384, out_features=16, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=16, out_features=384, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (7): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): SiLU()\n",
       "          (6): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=384, out_features=16, bias=True)\n",
       "              (1): SiLU()\n",
       "              (2): Linear(in_features=16, out_features=384, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (7): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (downscales): ModuleList(\n",
       "    (0): DownScaleLayer(\n",
       "      (downscale): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): DownScaleLayer(\n",
       "      (downscale): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): DownScaleLayer(\n",
       "      (downscale): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upscales): ModuleList(\n",
       "    (0): UpScaleLayer(\n",
       "      (upscale): Sequential(\n",
       "        (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "      )\n",
       "    )\n",
       "    (1): UpScaleLayer(\n",
       "      (upscale): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "      )\n",
       "    )\n",
       "    (2): UpScaleLayer(\n",
       "      (upscale): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_test = 14 #epoch + 1\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AbstractUNet(args_n).to(device)\n",
    "save_net = os.path.join(save_dir,\"models\",f\"epoch_{epoch_test}.pt\")\n",
    "model.load_state_dict(torch.load(save_net))\n",
    "model.eval()\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [-0.12777039408683777, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.1151360347867012, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.19182877242565155, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.21217769384384155, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.1551094949245453, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.12158118933439255, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.14564207196235657, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.15514594316482544, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.13279908895492554, 0.6745098233222961]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.19802765548229218, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.11892585456371307, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.16695056855678558, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.18332639336585999, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.18362917006015778, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.19844494760036469, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.14710737764835358, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.23262713849544525, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.16459092497825623, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.15038402378559113, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.15495191514492035, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.1729697734117508, 0.9725490212440491]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.2610151171684265, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.20300927758216858, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.20291787385940552, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.15762104094028473, 0.9215686321258545]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.16873852908611298, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.1801508069038391, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.18306033313274384, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.12369508296251297, 0.658823549747467]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.17358560860157013, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.13404977321624756, 0.7647058963775635]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.2009047418832779, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.21397706866264343, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.18392625451087952, 0.9098039269447327]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.14079150557518005, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.20563438534736633, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.16140572726726532, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.12773707509040833, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.15162813663482666, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.12147798389196396, 0.8823529481887817]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.22142626345157623, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.14665839076042175, 0.9529411792755127]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.20021235942840576, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.1820639669895172, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.2281239926815033, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.14858074486255646, 0.7254902124404907]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.1779511570930481, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.21437780559062958, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.16142702102661133, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.4489234983921051, 0.9529411792755127]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "from inpaint_tools import save_test_image\n",
    "from dataset import CatDataset\n",
    "\n",
    "settings[\"data_set\"] = \"test_200\"\n",
    "\n",
    "save_test_dir = os.path.join(save_dir,settings[\"data_set\"])\n",
    "pathlib.Path(save_test_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset_test = CatDataset(settings, test=True)\n",
    "dl_test = DataLoader(dataset_test, \n",
    "\t\t\t\tbatch_size=settings[\"batch_size\"],\n",
    "                shuffle=True,\n",
    "                num_workers=settings[\"num_workers\"])\n",
    "with torch.no_grad():\n",
    "    for batch in dl_test:\n",
    "        model_input, mask, im_id = batch\n",
    "        model_input, mask = model_input.to(device), mask.to(device)\n",
    "\n",
    "        outputs = model(model_input)\n",
    "        \n",
    "        for i in range(len(im_id)):\n",
    "            save_image_name = os.path.join(save_test_dir,f\"{im_id[i]}.png\")\n",
    "            save_test_image(save_image_name,outputs[i],mask[i],model_input[i])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
