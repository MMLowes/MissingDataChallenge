{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lowes\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from types import SimpleNamespace\n",
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models.efficient_unet import AbstractUNet\n",
    "from dataset import CatDataset\n",
    "from inpaint_tools import read_file_list\n",
    "from skimage import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"unet\": {\"block\": \"ffmmm\", #m=MBConv,f=FusedMBConv,u=Unet \n",
    "                    \"act\": \"silu\",\n",
    "                    \"res_mode\": \"cat\", #cat, add\n",
    "                    \"init_mode\": \"effecientnetv2\",\n",
    "                    \"downscale_mode\": \"avgpool\",\n",
    "                    \"upscale_mode\": \"bilinear\",\n",
    "                    \"input_channels\": 4,\n",
    "                    \"output_channels\": 3,\n",
    "                    \"num_blocks\": 5,\n",
    "                    \"num_c\": [8,16,32,48,64],\n",
    "                    \"num_repeat\": [1,2,2,4,4],\n",
    "                    \"expand_ratio\": [1,4,4,6,6],\n",
    "                    \"SE\": [0,0,1,1,1]\n",
    "                }}\n",
    "\n",
    "args = {\"unet\": {\"block\": \"ffmmm\", #m=MBConv,f=FusedMBConv,u=Unet \n",
    "                    \"act\": \"silu\",\n",
    "                    \"res_mode\": \"cat\", #cat, add\n",
    "                    \"init_mode\": \"effecientnetv2\",\n",
    "                    \"downscale_mode\": \"avgpool\",\n",
    "                    \"upscale_mode\": \"bilinear\",\n",
    "                    \"input_channels\": 4,\n",
    "                    \"output_channels\": 3,\n",
    "                    \"num_blocks\": 4,\n",
    "                    \"num_c\": [8,16,32,64],\n",
    "                    \"num_repeat\": [1,2,2,4],\n",
    "                    \"expand_ratio\": [1,4,4,6],\n",
    "                    \"SE\": [0,0,1,1]\n",
    "                }}\n",
    "args_n = json.loads(json.dumps(args), object_hook=lambda item: SimpleNamespace(**item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "net = AbstractUNet(args_n).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 360, 360])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.zeros((1,4,360,360)).to(device)\n",
    "output = net(test)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([4, 360, 360]), torch.Size([1, 360, 360]), torch.Size([3, 360, 360])]\n"
     ]
    }
   ],
   "source": [
    "settings = {\n",
    "\t\"team_data\":\n",
    "\t{\n",
    "\t\t\"name\": \"YourTeamNameHere\"\n",
    "\t},\n",
    "    \"training_parms\": {\n",
    "\t\t\"method\": \"YourMethodHere\",\n",
    "\t\t\"dummy_value\": 1000\n",
    "    },\n",
    "    \"dirs\": {\n",
    "            \"input_data_dir\": \"C:/Users/lowes/OneDrive/Skrivebord/DTU/summer_school_23/MissingDataChallenge/data/\",\n",
    "\t\t\t\"output_data_dir\": \"missing_data_output/\"\n",
    "\t},\n",
    "\t\"challenge_server\": {\n",
    "\t\t\"address\": \"http://fungi.compute.dtu.dk:8080\"\n",
    "\t},\n",
    "\t\"data_set\": \"training\",\n",
    "\t\"batch_size\": 2,\n",
    "\t\"num_workers\": 0,\n",
    "}\n",
    "\n",
    "\n",
    "dataset_train = CatDataset(settings)\n",
    "print([d.shape for d in dataset_train[0]])\n",
    "\n",
    "dl = DataLoader(dataset_train, \n",
    "\t\t\t\tbatch_size=settings[\"batch_size\"],\n",
    "                shuffle=True,\n",
    "                num_workers=settings[\"num_workers\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|â–Ž         | 66/2484 [00:10<06:35,  6.11batch/s, loss=2.88e+4]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17508\\1549905028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# Backpropagation and optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lowes\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lowes\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_train = CatDataset(settings)\n",
    "dl_train = DataLoader(dataset_train, \n",
    "\t\t\t\tbatch_size=settings[\"batch_size\"],\n",
    "                shuffle=True,\n",
    "                num_workers=settings[\"num_workers\"])\n",
    "\n",
    "settings[\"data_set\"] = \"validation_200\"\n",
    "dataset_val = CatDataset(settings)\n",
    "dl_val = DataLoader(dataset_val, \n",
    "\t\t\t\tbatch_size=settings[\"batch_size\"],\n",
    "                shuffle=True,\n",
    "                num_workers=settings[\"num_workers\"])\n",
    "\n",
    "# Create the model, loss function, and optimizer\n",
    "NUM_EPOCHS = 12\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AbstractUNet(args_n).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Create a progress bar using tqdm\n",
    "    with tqdm.tqdm(dl_train, unit=\"batch\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "            model_input, mask, image = batch\n",
    "            model_input, mask, image = model_input.to(device), mask.to(device), image.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(model_input)\n",
    "\n",
    "            loss = criterion(outputs*mask, image*mask)\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update progress bar description with loss\n",
    "            tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "            tepoch.set_postfix({\"loss\"=loss.item()})\n",
    "\n",
    "            # Accumulate loss for this epoch\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    # Calculate and print average loss for the epoch\n",
    "    average_loss = running_loss / len(train_loader)\n",
    "\n",
    "    for batch in dl_val:\n",
    "        model_input, mask, image = batch\n",
    "        model_input, mask, image = model_input.to(device), mask.to(device), image.to(device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
